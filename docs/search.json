[{"path":"/articles/estimate_comparisons.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Estimate Comparisons","text":"’ll focus single county (Arlington, VA), census block groups Public Use Microdata Samples (PUMS) primary source data. Ultimately, ’ll want use methods get values unobserved geographies, comparison methods, ’ll want way test results known values. test case, can simply start higher geolayer, make estimates block group level. , ’ll need aggregate block group data tracts:","code":"# directory to save data in base_dir <- \"../estimate_comparison\" dir.create(base_dir, FALSE) # geographies library(catchment) geography_bg <- download_census_shapes(base_dir, \"va\", \"bg\", year = 2021) geography_bg <- geography_bg[grep(\"^51013\", geography_bg$GEOID), ] geography_tr <- download_census_shapes(base_dir, \"va\", \"tr\", year = 2021) geography_tr <- geography_tr[grep(\"^51013\", geography_tr$GEOID), ]  # ACS data  ## block groups block_groups <- tidycensus::get_acs(   year = 2021,   state = \"51\",   county = \"013\",   geography = \"block group\",   output = \"wide\",   variables = c(     total = \"B01001_001\",     race_white = \"B02001_002\",     race_black = \"B02001_003\",     race_native = \"B02001_004\",     race_asian = \"B02001_005\",     sex_male = \"B01001_002\",     sex_female = \"B01001_026\",     tenure_total = \"B25003_001\",     tenure_owner = \"B25003_002\",     tenure_renter = \"B25003_003\",     income_total = \"B19001_001\",     income_lt10 = \"B19001_002\",     income_10_15 = \"B19001_003\",     income_15_20 = \"B19001_004\",     income_20_25 = \"B19001_005\",     income_25_30 = \"B19001_006\",     income_30_35 = \"B19001_007\",     income_35_40 = \"B19001_008\",     income_40_45 = \"B19001_009\",     income_45_50 = \"B19001_010\",     income_100_125 = \"B19001_014\",     income_125_150 = \"B19001_015\",     income_150_200 = \"B19001_016\",     income_gt200 = \"B19001_017\"   ) )[, -2] #> Getting data from the 2017-2021 5-year ACS colnames(block_groups)[2] <- \"Total\" block_groups$race_other <- block_groups$Total - rowSums(   block_groups[, grep(\"^race_.*E$\", colnames(block_groups))] ) colnames(block_groups) <- sub(\"E$\", \"\", colnames(block_groups)) block_groups <- block_groups[block_groups$Total != 0, ]  library(sf) rownames(geography_bg) <- geography_bg$GEOID st_geometry(block_groups) <- st_geometry(geography_bg[block_groups$GEOID, ])  # parcel data parcel_file <- paste0(base_dir, \"/parcels.rds\") if (!file.exists(parcel_file)) {   parcels <- st_read(paste0(     \"https://arlgis.arlingtonva.us/arcgis/rest/services/Open_Data/od_MHUD_Polygons/\",     \"FeatureServer/0/query?where=1=1&outFields=*&outSR=4326&f=json\"   ))   saveRDS(parcels, parcel_file, compress = \"xz\") } parcels <- readRDS(parcel_file) colnames(parcels)[colnames(parcels) == \"Total_Units\"] <- \"Total\" parcels$tract <- substring(parcels$Full_Block, 1, 11) parcels <- parcels[parcels$Year_Built <= 2021, ] tracts <- redistribute(block_groups, geography_tr)"},{"path":"/articles/estimate_comparisons.html","id":"methods","dir":"Articles","previous_headings":"","what":"Methods","title":"Estimate Comparisons","text":"baseline, first method consider proportional redistribution block group summary estimates alone.","code":""},{"path":[]},{"path":"/articles/estimate_comparisons.html","id":"direct","dir":"Articles","previous_headings":"Methods > Redistribution","what":"Direct","title":"Estimate Comparisons","text":"tracts block groups directly: can see case, error introduce proportional information lower level; block groups varied within tract value:","code":"# going from tracts to block groups with no information estimate_tr_to_bg <- redistribute(   tracts, block_groups,   source_id = \"id\" )  # mean absolute error between total population estimates mean(abs(estimate_tr_to_bg$Total - block_groups$Total)) #> [1] 303.938"},{"path":"/articles/estimate_comparisons.html","id":"down-and-up","dir":"Articles","previous_headings":"Methods > Redistribution","what":"Down and Up","title":"Estimate Comparisons","text":"tracts parcels, back block groups: Now original variation block groups:  parcel totals living units rather individuals, may able refine redistribution based heuristic estimates (tweaking) number people per living unit:","code":"# going from tracts to parcels map_tr_to_parcel <- redistribute(   tracts, parcels,   source_id = \"id\", target_id = \"OBJECTID\", return_map = TRUE ) estimate_tr_to_parcel <- redistribute(   tracts, parcels, map_tr_to_parcel,   weight = \"Total\", source_id = \"id\", target_id = \"OBJECTID\" )  # then from parcels to block groups map_parcel_to_bg <- redistribute(   estimate_tr_to_parcel, block_groups,   source_id = \"id\", target_id = \"GEOID\", return_map = TRUE ) estimate_parcel_to_bg <- redistribute(   estimate_tr_to_parcel, block_groups, map_parcel_to_bg,   source_id = \"id\", target_id = \"GEOID\" )  # mean absolute error between total population estimates mean(abs(estimate_parcel_to_bg$Total - block_groups$Total)) #> [1] 222.5203 # start with number of units parcels$Residents <- parcels$Total  ## for parcels with more than 1 unit, assume 2.255 per unit su <- parcels$Total > 1 parcels$Residents[su] <- parcels$Total[su] * 2.255  ## for 1-unit parcels, base on size su <- parcels$Total == 1 parcels$Residents[su] <- as.numeric(cut(   parcels$Shape__Area[su], c(-Inf, 9170, 9550, 48000, Inf) )) + 4 parcels$Residents[su & parcels$Residents > 7] <- 137.7  # now see if this improved our redistribution estimate_tr_to_parcel <- redistribute(   tracts, parcels, map_tr_to_parcel,   weight = \"Residents\", source_id = \"id\", target_id = \"OBJECTID\" ) estimate_parcel_to_bg <- redistribute(   estimate_tr_to_parcel, block_groups, map_parcel_to_bg,   source_id = \"id\", target_id = \"GEOID\" )  # mean absolute error between total population estimates mean(abs(estimate_parcel_to_bg$Total - block_groups$Total)) #> [1] 180.7739"},{"path":[]},{"path":"/articles/estimate_comparisons.html","id":"pums-associations","dir":"Articles","previous_headings":"Methods > Estimation","what":"PUMS Associations","title":"Estimate Comparisons","text":"far, ’ve used additional information (total units) parcel level improve distribution values across block groups, relative uniform distribution. information parcel level, unit type number renter versus owner residents, make use information, need association source values features. census microdata sample can come : Public Use Microdata Sample (PUMS) consists individual-level observations include demographic features housing features. PUM sample located PUM areas, made tracts, can start baseline. use associations demographic housing features within PUMA get probabilities parcel level, redistribute source values like . first step end prepare data easy associate individual PUMS variables per-level summaries tract level: Now can apply method set data.","code":"pums <- download_census_pums(base_dir, \"va\", 2021) #> ℹ loading household sample: h1-Year.csv.xz #> ℹ loading person sample: p1-Year.csv.xz #> ℹ loading crosswalk 2020_Census_Tract_to_2020_PUMA.txt  # prepare IDs pums$crosswalk$GEOID <- do.call(paste0, pums$crosswalk[, 1:3]) pums$person$ID <- do.call(paste0, pums$person[, c(\"SERIALNO\", \"SPORDER\")])  # prepare variables  ## survey categories pums$person$sex_cat <- c(\"sex_male\", \"sex_female\")[as.numeric(pums$person$SEX)]  pums$person$race_cat <- paste0(\"race_\", c(   \"white\", \"black\", rep(\"native\", 3), \"asian\", rep(\"other\", 3) ))[as.numeric(pums$person$RAC1P)]  income_cols <- grep(\"income_\\\\d[_0-9]+$\", colnames(tracts)) pums$household$income_cat <- as.character(cut(pums$household$HINCP, c(   -Inf, as.integer(gsub(\"^income_|_[0-9]+$\", \"\", colnames(tracts)[income_cols])),   200, Inf ), c(\"income_lt10\", colnames(tracts)[income_cols], \"income_gt200\")))  ## unit categories pums$household$building_type <- \"OTHER\" pums$household$building_type[pums$household$BLD == \"02\"] <- \"SFD\" pums$household$building_type[pums$household$BLD == \"03\"] <- \"SFA\" pums$household$building_type[   is.na(pums$household$BLD) | pums$household$BLD %in% paste0(\"0\", 4:9) ] <- \"MULTI\" pums$household <- pums$household[pums$household$building_type != \"OTHER\", ]  pums$household$status <- \"OTHER\" pums$household$status[pums$household$TEN %in% 1:2] <- \"OWNER\" pums$household$status[pums$household$TEN == 3] <- \"RENTER\" pums$household <- pums$household[pums$household$status != \"OTHER\", ] # define variables of interest vars_house <- c(   ID = \"SERIALNO\", weight = \"WGTP\", type = \"building_type\",   status = \"status\", income = \"income_cat\" ) vars_person <- c(   ID = \"ID\", weight = \"PWGTP\", sex_cat = \"sex_cat\", race_cat = \"race_cat\" ) vars_units <- c(   type = \"Unit_Type\", renters = \"Renter_Occupied\", owners = \"Owner_Occupied\" )  ## get their levels vars_list <- c(   lapply(vars_person[-(1:2)], function(var) unique(pums$person[[var]])),   income_cat = list(unique(pums$household$income_cat)) ) vars <- unlist(vars_list, use.names = FALSE) return_vars <- names(vars_list)  # prepare datasets split into PUMAs pumas_focal <- unique(pums$crosswalk$PUMA5CE[pums$crosswalk$GEOID %in% tracts$id]) data <- lapply(structure(pumas_focal, names = pumas_focal), function(puma) {   households <- pums$household[pums$household$PUMA == puma, vars_house]   ids <- pums$crosswalk$GEOID[     pums$crosswalk$PUMA5CE == puma & pums$crosswalk$GEOID %in% tracts$id   ]   list(     households = households,     individuals = do.call(rbind, lapply(seq_len(nrow(households)), function(r) {       h <- households[r, ]       d <- pums$person[pums$person$SERIALNO == h$SERIALNO, vars_person]       cbind(h[rep(1L, nrow(d)), ], d)     })),     source = tracts[tracts$id %in% ids, c(\"id\", vars), drop = TRUE],     parcels = parcels[       parcels$tract %in% ids, c(\"tract\", \"OBJECTID\", vars_units), drop = TRUE     ]   ) })  # function to apply each method to the data apply_method <- function(data, method) {   do.call(rbind, lapply(data, function(set) {     do.call(rbind, lapply(unique(set$source$id), function(id) {       source <- set$source[set$source$id == id, -1]       target <- set$parcels[set$parcels$tract == id, ]       if (nrow(target)) {         est <- method(source, target[, -1], set$individuals)         su <- !vars %in% colnames(est)         if (any(su)) est[, vars[su]] <- 0         cbind(target[, 1:2], est[as.character(target$OBJECTID), vars])       }     }))   })) }"},{"path":"/articles/estimate_comparisons.html","id":"initial-weights","dir":"Articles","previous_headings":"Methods > Estimation","what":"Initial Weights","title":"Estimate Comparisons","text":"","code":"est_baseline <- function(source, target, individuals) {   do.call(rbind, lapply(unique(target$Unit_Type), function(type) {     d <- target[target$Unit_Type == type, ]     nd <- nrow(d)     colnames(d)[-(1:2)] <- c(\"RENTER\", \"OWNER\")     i <- individuals[       individuals$building_type == type, c(\"PWGTP\", \"status\", return_vars)     ]     as.data.frame(Reduce(\"+\", lapply(unique(i$status), function(s) {       ii <- i[i$status == s, ]       do.call(cbind, lapply(return_vars, function(cat) {         props <- tapply(ii$PWGTP, ii[[cat]], sum) / sum(ii$PWGTP)         props[vars_list[[cat]][!vars_list[[cat]] %in% names(props)]] <- 0         props[is.na(props)] <- 0         matrix(           d[[s]] * rep(props, each = nd),           nd, dimnames = list(d$OBJECTID, names(props))         )       }))     })))   })) } estimate_parcel_baseline <- apply_method(data, est_baseline) estimate_baseline_to_bg <- redistribute(   estimate_parcel_baseline[, -1], block_groups, map_parcel_to_bg,   source_id = \"OBJECTID\", target_id = \"GEOID\" )"},{"path":"/articles/estimate_comparisons.html","id":"two-step-raking","dir":"Articles","previous_headings":"Methods > Estimation","what":"Two Step Raking","title":"Estimate Comparisons","text":"","code":"library(anesrake) twostep_prep <- function() {   eval(expression({     for (var in names(totals)) {       individuals[[var]] <- as.factor(individuals[[var]])       totals[[var]] <- totals[[var]][levels(individuals[[var]])]       su <- which(is.na(totals[[var]]) | totals[[var]] == 0)       if (length(su)) {         individuals <- individuals[!individuals[[var]] %in% names(su), ]         individuals[[var]] <- droplevels(individuals[[var]], exclude = names(su))         totals[[var]] <- totals[[var]][levels(individuals[[var]])]       }       totals[[var]] <- totals[[var]] / sum(totals[[var]])     }     totals <- Filter(length, totals)   }), parent.frame()) } est_twostep <- function(source, target, individuals) {   # step 1: initial weights at household level   totals <- list(     building_type = tapply(rowSums(target[, -(1:2)]), target$Unit_Type, sum),     status = structure(colSums(target[, -(1:2)]), names = c(\"RENTER\", \"OWNER\")),     income_cat = unlist(source[, grep(\"^income_\", colnames(source))])   )   twostep_prep()    capture.output(individuals$weight <- tryCatch(     anesrake(       totals, individuals, individuals$SERIALNO, individuals$WGTP,       pctlim = .001     )$weightvec[individuals$SERIALNO],     error = function(e) {       warning(e$message)       individuals$WGTP     }   ))      # step 2: adjust at person level   totals <- lapply(     structure(names(vars_list)[1:2], names = names(vars_list)[1:2]),     function(n) unlist(source[, vars_list[[n]]])   )   twostep_prep()    capture.output(individuals$weight <- tryCatch(     anesrake(       totals, individuals, individuals$ID,       individuals$PWGTP * individuals$weight / individuals$WGTP,       pctlim = .001     )$weightvec[individuals$ID],     error = function(e) {       warning(e$message)       individuals$PWGTP * individuals$weight / individuals$WGTP     }   ))    # calculate proportions, and estimate parcel values   do.call(rbind, lapply(unique(target$Unit_Type), function(type) {     d <- target[target$Unit_Type == type, ]     nd <- nrow(d)     colnames(d)[-(1:2)] <- c(\"RENTER\", \"OWNER\")     i <- individuals[       individuals$building_type == type, c(\"weight\", \"status\", return_vars)     ]     as.data.frame(Reduce(\"+\", lapply(levels(i$status), function(s) {       ii <- i[i$status == s, ]       do.call(cbind, lapply(return_vars, function(cat) {         props <- tapply(ii$weight, ii[[cat]], sum) / sum(ii$weight)         props[is.na(props)] <- 0         matrix(           d[[s]] * rep(props, each = nd),           nd, dimnames = list(d$OBJECTID, names(props))         )       }))     })))   })) } estimate_parcel_twostep <- apply_method(data, est_twostep) estimate_twostep_to_bg <- redistribute(   estimate_parcel_twostep[, -1], block_groups, map_parcel_to_bg,   source_id = \"OBJECTID\", target_id = \"GEOID\" )"},{"path":"/articles/estimate_comparisons.html","id":"generalized-raking","dir":"Articles","previous_headings":"Methods > Estimation","what":"Generalized Raking","title":"Estimate Comparisons","text":"","code":"library(mlfit) est_grake <- function(source, target, individuals) {   person <- lapply(names(vars_list)[1:2], function(n) {     l <- vars_list[[n]]     s <- data.frame(level = l, count = as.numeric(source[, l]))     colnames(s)[1] <- n     s   })   household <- unique(individuals$building_type)   household <- structure(numeric(length(household)), names = household)   observed_types <- tapply(rowSums(target[, -(1:2)]), target$Unit_Type, sum)   household[names(observed_types)] <- observed_types   household <- list(data.frame(building_type = names(household), count = household))   household[[1]]$count[is.na(household[[1]]$count)] <- 0   household[[2]] <- data.frame(     status = c(\"RENTER\", \"OWNER\"), count = colSums(target[, -(1:2)])   )   household[[3]] <- unlist(source[, grep(\"^income_\", colnames(source))])   household[[3]] <- data.frame(     income_cat = names(household[[3]]), count = household[[3]]   )   names(household) <- c(\"building_type\", \"status\", \"income_cat\")   household <- lapply(names(household), function(var) {     l <- household[[var]]     l[l[[1]] %in% unique(individuals[, var]),]   })   m <- ml_problem(     individuals,     field_names = special_field_names(\"SERIALNO\", \"ID\", count = \"count\"),     group_controls = household,     individual_controls = person,     prior_weights = individuals$WGTP   )   individuals$weight <- tryCatch(     suppressWarnings(ml_fit_dss(m)$weights),     error = function(e) {       warning(e$message)       individuals$PWGTP     }   )   # if (all(individuals$WGTP == individuals$weight)) browser()   do.call(rbind, lapply(unique(target$Unit_Type), function(type) {     d <- target[target$Unit_Type == type, ]     nd <- nrow(d)     colnames(d)[-(1:2)] <- c(\"RENTER\", \"OWNER\")     i <- individuals[       individuals$building_type == type, c(\"weight\", \"status\", return_vars)     ]     as.data.frame(Reduce(\"+\", lapply(unique(i$status), function(s) {       ii <- i[i$status == s, ]       do.call(cbind, lapply(return_vars, function(cat) {         props <- tapply(ii$weight, ii[[cat]], sum) / sum(ii$weight)         props[vars_list[[cat]][!vars_list[[cat]] %in% names(props)]] <- 0         props[is.na(props)] <- 0         matrix(           d[[s]] * rep(props, each = nd),           nd, dimnames = list(d$OBJECTID, names(props))         )       }))     })))   })) } estimate_parcel_grake <- apply_method(data, est_grake) estimate_grake_to_bg <- redistribute(   estimate_parcel_grake[, -1], block_groups, map_parcel_to_bg,   source_id = \"OBJECTID\", target_id = \"GEOID\" )"},{"path":"/articles/estimate_comparisons.html","id":"comparison","dir":"Articles","previous_headings":"Methods > Estimation","what":"Comparison","title":"Estimate Comparisons","text":"","code":"error <- data.frame(   \"Proportional\" = vapply(vars, function(var) {     mean(abs(estimate_parcel_to_bg[[var]] - block_groups[[var]]))   }, 0),   \"Baseline\" = vapply(vars, function(var) {     mean(abs(estimate_baseline_to_bg[[var]] - block_groups[[var]]))   }, 0),\"Two Step\" = vapply(vars, function(var) {     mean(abs(estimate_twostep_to_bg[[var]] - block_groups[[var]]))   }, 0),   \"Generalized\" = vapply(vars, function(var) {     mean(abs(estimate_grake_to_bg[[var]] - block_groups[[var]]))   }, 0),   check.names = FALSE ) error <- rbind(error, Average = colMeans(error)) kable(error)"},{"path":"/articles/introduction.html","id":"basic-example","dir":"Articles","previous_headings":"","what":"Basic Example","title":"Introduction to Redistribution","text":"Say 1 set 5 regions:","code":"regions <- data.frame(id = 1:5) regions #>   id #> 1  1 #> 2  2 #> 3  3 #> 4  4 #> 5  5"},{"path":"/articles/introduction.html","id":"disaggregate","dir":"Articles","previous_headings":"Basic Example","what":"Disaggregate","title":"Introduction to Redistribution","text":"single observation entire set, disaggregate regions. additional information, best guess value region proportional split – case, one fifth observed value region: , maybe know little regions, size; use information adjust proportion allotted region:","code":"# install if needed: remotes::install_github(\"uva-bi-sdad/redistribute\") library(redistribute)  set_value <- 1 (redistribute(set_value, regions, verbose = TRUE)) #>  [36mℹ [39m source IDs:  [32m [32m1 [32m [39m #>  [36mℹ [39m target IDs:  [32m [32mid [32m [39m column of `target` #>  [36mℹ [39m map: all target IDs for single source #>  [36mℹ [39m weights:  [32m [32m1 [32m [39m #>  [36mℹ [39m redistributing  [32m [32m1 [32m [39m variable from  [32m [32m1 [32m [39m source to  [32m [32m5 [32m [39m targets: #>  [36m• [39m (numb; 1) V1 #>   [36mℹ [39m disaggregating...   [32m✔ [39m done disaggregating  [38;5;249m[8ms] [39m #>   id  V1 #> 1  1 0.2 #> 2  2 0.2 #> 3  3 0.2 #> 4  4 0.2 #> 5  5 0.2 region_values <- redistribute(   set_value, regions,   weight = c(1, 10, 10, 20, 50), verbose = TRUE ) #>  [36mℹ [39m source IDs:  [32m [32m1 [32m [39m #>  [36mℹ [39m target IDs:  [32m [32mid [32m [39m column of `target` #>  [36mℹ [39m map: all target IDs for single source #>  [36mℹ [39m weights: `weight` vector #>  [36mℹ [39m redistributing  [32m [32m1 [32m [39m variable from  [32m [32m1 [32m [39m source to  [32m [32m5 [32m [39m targets: #>  [36m• [39m (numb; 1) V1 #>   [36mℹ [39m disaggregating...   [32m✔ [39m done disaggregating  [38;5;249m[7ms] [39m region_values #>   id         V1 #> 1  1 0.01098901 #> 2  2 0.10989011 #> 3  3 0.10989011 #> 4  4 0.21978022 #> 5  5 0.54945055"},{"path":"/articles/introduction.html","id":"aggregate","dir":"Articles","previous_headings":"Basic Example","what":"Aggregate","title":"Introduction to Redistribution","text":"observations regions, aggregate single value set. case, can re-aggregate initially disaggregated, recover original observation:","code":"(redistribute(region_values, verbose = TRUE)) #>  [36mℹ [39m source IDs:  [32m [32mid [32m [39m column of `source` #>  [36mℹ [39m target IDs:  [32m [32m1 [32m [39m #>  [36mℹ [39m map: all source IDs to a single target #>  [36mℹ [39m weights:  [32m [32m1 [32m [39m #>  [36mℹ [39m redistributing  [32m [32m1 [32m [39m variable from  [32m [32m5 [32m [39m sources to  [32m [32m1 [32m [39m target: #>  [36m• [39m (numb; 1) V1 #>   [36mℹ [39m aggregating...   [32m✔ [39m done aggregating  [38;5;249m[7ms] [39m #>   id V1 #> 1  1  1"},{"path":"/articles/introduction.html","id":"applied-example","dir":"Articles","previous_headings":"","what":"Applied Example","title":"Introduction to Redistribution","text":"One use case redistribution converting demographics data geographic layers. illustration, can look U.S. Census data Fairfax, Virginia: population information provided Census Block Group level lowest, might want look population within zip codes. try aggregating directly block groups zip codes, involves calculating proportional intersections region polygons: also disaggregate parcel level, point locations, aggregate zipcodes: Now can compare estimated total population different methods provided:","code":"base_dir <- \"~/Downloads\" # remotes::install_github(\"uva-bi-sdad/catchment\") library(catchment) library(sf)  # download population and data shapes population <- download_census_population(base_dir, \"VA\", 2020)$estimates #> ℹ downloading Virginia American Community Survey summary files #> ℹ decompressing Virginia American Community Survey summary files #> ℹ reformatting Virginia American Community Survey summary files #> ℹ writing Virginia files #> ✔ wrote file: #> •  population <- population[grepl(\"^51(?:059|600)\", population$GEOID), ] population[, -1] <- vapply(   population[, -1], as.numeric, numeric(nrow(population)) ) rownames(population) <- population$GEOID block_groups <- st_transform(   download_census_shapes(base_dir, \"VA\", \"bg\", year = 2020), \"WGS84\" ) #> Writing layer `cb_2020_51_bg_500k' to data source  #>   `../../introduction/cb_2020_51_bg_500k.geojson' using driver `GeoJSON' #> Writing 5951 features with 11 fields and geometry type Multi Polygon. block_groups <- block_groups[block_groups$GEOID %in% population$GEOID, ] population <- population[block_groups$GEOID, ] st_geometry(population) <- block_groups$geometry population$Overall <- population$TOTAL.POPULATION_Total  # prepare a map library(leaflet) pal <- colorNumeric(scico::scico(255, palette = \"lajolla\"), population$Overall) map <- leaflet(   population,   options = leafletOptions(attributionControl = FALSE) ) |>   addProviderTiles(\"CartoDB.Positron\") |>   addScaleBar(\"bottomleft\") |>   addControl(\"Total Population\", \"topright\") |>   addLayersControl(     position = \"topleft\", overlayGroups = \"Block Groups\",     baseGroups = c(       \"Zip Codes\", \"Parcels -> Zip Codes\", \"Block Groups -> Zip Codes\",       \"Block Groups -> Parcels -> Zip Codes\"     )   ) |>   addLegend(     \"bottomright\", pal, ~Overall,     title = \"Block Groups\", opacity = 1   ) |>   addPolygons(     fillColor = ~ pal(Overall), fillOpacity = 1, weight = 1,     color = \"#000\", highlightOptions = highlightOptions(color = \"#fff\"),     group = \"Block Groups\", label = ~ paste(       GEOID, \"Population:\", round(Overall, 3)     )   ) # Download shapes if needed zipcode_file <- paste0(base_dir, \"/zipcode_va_fairfax.geojson\") if (!file.exists(zipcode_file)) {   download.file(paste0(     \"https://www.fairfaxcounty.gov/euclid/rest/services/IPLS/IPLSMap\",     \"/MapServer/3/query?where=1=1&outFields=*&outSR=4326&f=geojson\"   ), zipcode_file) } zipcodes <- read_sf(zipcode_file)  # redistribute population data from block groups zipcode_population <- redistribute(   population, zipcodes,   target_id = \"ZIPCODE\", verbose = TRUE ) #>  [36mℹ [39m source IDs:  [32m [32mGEOID [32m [39m column of `source` #>  [36mℹ [39m target IDs:  [32m [32mZIPCODE [32m [39m column of `target` #>  [36mℹ [39m map: intersections between geometries #>   [36mℹ [39m mapping...   [32m✔ [39m done mapping  [38;5;249m[7.1s] [39m #>  [36mℹ [39m weights:  [32m [32m1 [32m [39m #>  [36mℹ [39m redistributing  [32m [32m116 [32m [39m variables from  [32m [32m693 [32m [39m sources to  [32m [32m80 [32m [39m targets: #>  [36m• [39m (numb; 116) #>   [36mℹ [39m aggregating...   [32m✔ [39m done aggregating  [38;5;249m[9ms] [39m # Download shapes if needed ## https://data-fairfaxcountygis.opendata.arcgis.com/datasets/current-population parcel_file <- paste0(base_dir, \"/parcel_va_fairfax.geojson\") if (!file.exists(parcel_file)) {   download.file(paste0(     \"https://opendata.arcgis.com/api/v3/datasets/\",     \"314bfe4019754952a715be3a33384d9d_0/downloads/data\",     \"?format=geojson&spatialRefId=4326&where=1=1\"   ), parcel_file) } parcels <- read_sf(parcel_file)  # disaggregate population data from block groups to parcels bg_parcel_population <- redistribute(   population, parcels,   weight = \"CURRE_POPUL\", verbose = TRUE ) #>  [36mℹ [39m source IDs:  [32m [32mGEOID [32m [39m column of `source` #>  [36mℹ [39m target IDs: sequence, assuming map from geometries #>  [36mℹ [39m map: intersections between geometries #>   [36mℹ [39m mapping...   [32m✔ [39m done mapping  [38;5;249m[2.2s] [39m #>  [36mℹ [39m weights:  [32m [32mCURRE_POPUL [32m [39m column of `target` #>  [36mℹ [39m  [32m [32m32 [32m [39m of  [32m [32m336407 [32m [39m target IDs were dropped because they were not present in `map` #>  [36mℹ [39m redistributing  [32m [32m116 [32m [39m variables from  [32m [32m693 [32m [39m sources to  [32m [32m336375 [32m [39m targets: #>  [36m• [39m (numb; 116) #>   [36mℹ [39m disaggregating...   [32m✔ [39m done disaggregating  [38;5;249m[2.6s] [39m #>  [36mℹ [39m realigning with original target IDs  # then aggregate from parcels to zip codes bg_parcel_zipcode_population <- redistribute(   bg_parcel_population, zipcodes,   source_id = \"id\", target_id = \"ZIPCODE\", verbose = TRUE ) #>  [36mℹ [39m source IDs:  [32m [32mid [32m [39m column of `source` #>  [36mℹ [39m target IDs:  [32m [32mZIPCODE [32m [39m column of `target` #>  [36mℹ [39m map: intersections between geometries #>   [36mℹ [39m mapping...   [32m✔ [39m done mapping  [38;5;249m[3.5s] [39m #>  [36mℹ [39m weights:  [32m [32m1 [32m [39m #>  [36mℹ [39m  [32m [32m25 [32m [39m of  [32m [32m80 [32m [39m target IDs were dropped because they were not present in `map` #>  [36mℹ [39m redistributing  [32m [32m116 [32m [39m variables from  [32m [32m336407 [32m [39m sources to  [32m [32m55 [32m [39m targets: #>  [36m• [39m (numb; 116) #>   [36mℹ [39m aggregating...   [32m✔ [39m done aggregating  [38;5;249m[9.4s] [39m #>  [36mℹ [39m realigning with original target IDs  # since it's provided in this case, we can also just aggregate # up from parcels directly parcel_zipcode_population <- redistribute(   parcels, zipcodes,   source_id = \"PIN\", target_id = \"ZIPCODE\", verbose = TRUE ) #>  [36mℹ [39m source IDs:  [32m [32mPIN [32m [39m column of `source` #>  [36mℹ [39m target IDs:  [32m [32mZIPCODE [32m [39m column of `target` #>  [36mℹ [39m map: intersections between geometries #>   [36mℹ [39m mapping...   [32m✔ [39m done mapping  [38;5;249m[3.3s] [39m #>  [36mℹ [39m weights:  [32m [32m1 [32m [39m #>  [36mℹ [39m  [32m [32m25 [32m [39m of  [32m [32m80 [32m [39m target IDs were dropped because they were not present in `map` #>  [36mℹ [39m redistributing  [32m [32m7 [32m [39m variables from  [32m [32m336407 [32m [39m sources to  [32m [32m55 [32m [39m targets: #>  [36m• [39m (numb; 5) OBJECTID, PARCE_ID, CURRE_POPUL, LOW_ESTIM_POPUL, HIGH_ESTIM_POPUL #>  [36m• [39m (char; 2) VALID_FROM, VALID_TO #>   [36mℹ [39m aggregating...   [32m✔ [39m done aggregating  [38;5;249m[9.5s] [39m #>  [36mℹ [39m re-converting categorical levels #>  [36mℹ [39m realigning with original target IDs all_values <- c(   zipcodes$POPULATION, zipcode_population$Overall,   bg_parcel_zipcode_population$Overall, parcel_zipcode_population$CURRE_POPUL ) pal_zip <- colorNumeric(scico::scico(255, palette = \"lajolla\"), all_values) map |>   addPolygons(     data = zipcodes,     fillColor = ~ pal_zip(POPULATION), fillOpacity = .8, weight = 1,     color = \"#000\", highlightOptions = highlightOptions(color = \"#fff\"),     group = \"Zip Codes\", label = ~ paste(       ZIPCODE, \"Population:\", round(POPULATION, 3)     )   ) |>   hideGroup(\"Zip Codes\") |>   addPolygons(     data = parcel_zipcode_population,     fillColor = ~ pal_zip(CURRE_POPUL), fillOpacity = .8, weight = 1,     color = \"#000\", highlightOptions = highlightOptions(color = \"#fff\"),     group = \"Parcels -> Zip Codes\", label = ~ paste(       id, \"Population:\", round(CURRE_POPUL, 3)     )   ) |>   hideGroup(\"Parcels -> Zip Codes\") |>   addPolygons(     data = zipcode_population,     fillColor = ~ pal_zip(Overall), fillOpacity = .8, weight = 1,     color = \"#000\", highlightOptions = highlightOptions(color = \"#fff\"),     group = \"Block Groups -> Zip Codes\", label = ~ paste(       id, \"Population:\", round(Overall, 3)     )   ) |>   hideGroup(\"Block Groups -> Zip Codes\") |>   addPolygons(     data = bg_parcel_zipcode_population,     fillColor = ~ pal_zip(Overall), fillOpacity = .8, weight = 1,     color = \"#000\", highlightOptions = highlightOptions(color = \"#fff\"),     group = \"Block Groups -> Parcels -> Zip Codes\", label = ~ paste(       id, \"Population:\", round(Overall, 3)     )   ) |>   showGroup(\"Block Groups -> Parcels -> Zip Codes\") |>   addLegend(\"bottomright\", pal_zip, all_values, opacity = 1, title = \"Zip Codes\")"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Biocomplexity Institute. Copyright holder, funder. Micah Iserman. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Iserman M (2023). redistribute: Redistribute Data. R package version 0.0.1, https://github.com/uva-bi-sdad/redistribute.","code":"@Manual{,   title = {redistribute: Redistribute Data},   author = {Micah Iserman},   year = {2023},   note = {R package version 0.0.1},   url = {https://github.com/uva-bi-sdad/redistribute}, }"},{"path":"/index.html","id":"redistribute","dir":"","previous_headings":"","what":"Redistribute Data","title":"Redistribute Data","text":"R package redistribute data. data redistributed (source) observed given frame (across rows associated IDs). data redistributed new frames (target; different rows IDs mapped source). Generally, frames represent groupings, lowest-level frame contains single observations (e.g., individual, individual single time-point, time-point single source, etc.), highest-level frame single observation entire population. example, U.S. Census Bureau releases data different geolevels, county, tract, block group, increasingly lower-level (higher-resolution). represent different frames observations might redistributed. useful observations one frame, want observations another. Frames may also roughly level (similar observation-group sizes), arranged differently (e.g., group individuals along different dimensions). case, might best redistribute data lower-level frame, back higher-level frame.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Redistribute Data","text":"Download R r-project.org, install package R console: load package:","code":"# install.packages(\"remotes\") remotes::install_github(\"uva-bi-sdad/redistribute\") library(redistribute)"},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 redistribute authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/reference/download_census_pums.html","id":null,"dir":"Reference","previous_headings":"","what":"Download U.S. Census Microdata — download_census_pums","title":"Download U.S. Census Microdata — download_census_pums","text":"Download load U.S. census American Community Survey (ACS) Public Use Microdata Samples (PUMS): (census.gov/programs-surveys/acs/microdata.html)[https://www.census.gov/programs-surveys/acs/microdata.html]","code":""},{"path":"/reference/download_census_pums.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download U.S. Census Microdata — download_census_pums","text":"","code":"download_census_pums(dir, state, year = 2021, level = \"both\",   one_year = TRUE, calculate_error = FALSE, crosswalk = TRUE,   geoids = NULL, verbose = TRUE)"},{"path":"/reference/download_census_pums.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download U.S. Census Microdata — download_census_pums","text":"dir Directory save file(s). state Postal FIPS code state. year 4 digit year, 2005 recent year. level character indicating whether get person- household-level sample. Defaults . one_year Logical; FALSE, get 5-year estimates rather 1-year file. specified, fall back 5-year file 1-year file available. calculate_error Logical; TRUE, calculate standard errors variable using Successive Difference Replicate Formula [PUMS handbook](https://www.census.gov/programs-surveys/acs/library/handbooks/pums.html). crosswalk Logical; FALSE, retrieve PUMA relationship files associating Census tracts PUM areas. treated TRUE geoids specified. geoids vector county, tract, block group GEOIDs within specified state select PUM areas ; defaults areas. specified, crosswalk treated TRUE. verbose Logical; FALSE, print status messages.","code":""},{"path":"/reference/download_census_pums.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download U.S. Census Microdata — download_census_pums","text":"list entries year state (specified), dictionary (containing data dictionary year), household /person (survey data), optionally household_error /person_error (calculate_error TRUE), crosswalk (crosswalk TRUE geoids specified).","code":""},{"path":"/reference/download_census_pums.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download U.S. Census Microdata — download_census_pums","text":"","code":"if (FALSE) { download_census_pums(\".\", \"va\") }"},{"path":"/reference/generate_population.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a Population — generate_population","title":"Generate a Population — generate_population","text":"Simulate population individuals within households, complex relationships demographic location features.","code":""},{"path":"/reference/generate_population.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a Population — generate_population","text":"","code":"generate_population(N = 1000, regions = NULL, capacities = NULL,   attraction_loci = 2, random_regions = 0.1, cost_loci = 2,   size_loci = 2, similarity_metric = \"euclidean\", n_neighbors = 50,   neighbor_range = 0.5, n_races = 6, verbose = FALSE)"},{"path":"/reference/generate_population.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a Population — generate_population","text":"N Number initial individuals generate. Final number individuals larger. regions vector region IDs, matrix coordinates, sf object geometries coordinates can derived. specified (capacities specified), regions similar housing units (mix single multi-family locations) generated. capacities vector maximum number households entry regions. attraction_loci Number locations selected centers attractiveness, influence households located. random_regions number 0 1, determines proportion people randomly relocated, case capacity households. cost_loci Number locations selected centers cost, influences initial income associated households. size_loci Number locations selected centers size, influence household sizes. similarity_metric Name metric use calculate nearness neighbors; see lma_simets. n_neighbors Number neighbors used influence new household's initial age race. neighbor_range Minimum similarity people considered neighbors, 0 1 (0 means unrestricted, 1 means region ). n_races Number different race groups sample . verbose Logical; TRUE, show status messages.","code":""},{"path":"/reference/generate_population.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a Population — generate_population","text":"list entries params (initial settings), two data.frames: households   individuals","code":""},{"path":"/reference/generate_population.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate a Population — generate_population","text":"population generated two steps: First, households generated placed within regions. Placement within regions determined total distance one regions selected attraction loci. coordinates provided, first randomly generated. households placed, household sizes incomes (first member) generated independent spacial loci. Renting status generated based income: 60% chance income mean income, 40% otherwise. Second, individuals generated household. generate individual, first, neighbors searched , based n_neighbors neighbor_range. neighbors summarized: average age income, tabulated race. affect first member household: age first drawn Beta distribution (shapes 1 2 renting 1.5 otherwise, multiplied 80) added 18, adjusted toward random value centered average neighbor age (floored Gaussian standard deviation 1), race sampled (highest result Binomial draw n_races trials proportion neighbors * base rate chance success race group). Neighbors also affect income second member household first member's income neighbor mean income (40,000 given neighbors); case, second member's income drawn Gaussian distribution centered first member's income, standard deviation 10,000. second member's age based first member; floored Gaussian centered first member's age, standard deviation 15 first member's age 40, 5 otherwise, trimmed 18 90. second member's race 70% chance first member, 30% chance selected like first member's. Members second income, age randomly selected uniform distribution 0 first member's age minus 15 (rounded ), race determined either first second member (50% chance). Sex 50% chance 0 1 second member; sex 10% chance first member's, 90% chance opposite.","code":""},{"path":"/reference/generate_population.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a Population — generate_population","text":"","code":"generate_population(2) #> $params #> $params$neighbors #> [1] 50 #>  #> $params$range #> [1] 0.5 #>  #> $params$races_rates #> [1] 0.353589492 0.500000000 0.009949772 0.070386214 0.104273899 0.443561723 #>  #>  #> $households #>   household region head_income size renting #> 1         1      1       59500    2       1 #> 2         2      2       65692    1       0 #>  #> $individuals #>   household person neighbors age sex race income #> 1         1      1         0  42   0    1  59500 #> 2         1      2         0  25   1    1  52018 #> 3         2      3         0  26   1    1  65692 #>"},{"path":"/reference/make_parent_polygons.html","id":null,"dir":"Reference","previous_headings":"","what":"Make Higher-Order Polygons — make_parent_polygons","title":"Make Higher-Order Polygons — make_parent_polygons","text":"Randomly combine given polygons contiguous, larger polygons.","code":""},{"path":"/reference/make_parent_polygons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make Higher-Order Polygons — make_parent_polygons","text":"","code":"make_parent_polygons(polygons, n = 2, strict_n = TRUE, verbose = TRUE)"},{"path":"/reference/make_parent_polygons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make Higher-Order Polygons — make_parent_polygons","text":"polygons sf object polygons reformed. n Number polygons aim combine new polygon. strict_n Logical; TRUE (default), n represents number intersecting polygons select, depending availability (minimum 2). FALSE, n represents number nearest polygons (centroid) use calculating box use selecting polygons (minimum 1). verbose Logical; FALSE, print status messages.","code":""},{"path":"/reference/make_parent_polygons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make Higher-Order Polygons — make_parent_polygons","text":"list entries new (sf object containing new polygons) map (list mapping old new polygon indices).","code":""},{"path":"/reference/redistribute.html","id":null,"dir":"Reference","previous_headings":"","what":"Redistribute Data — redistribute","title":"Redistribute Data — redistribute","text":"Distribute data source frame target frame.","code":""},{"path":"/reference/redistribute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Redistribute Data — redistribute","text":"","code":"redistribute(source, target = NULL, map = list(), source_id = \"GEOID\",   target_id = source_id, weight = NULL, source_variable = NULL,   source_value = NULL, aggregate = NULL, weight_agg_method = \"auto\",   outFile = NULL, overwrite = FALSE, make_intersect_map = FALSE,   overlaps = \"keep\", use_all = TRUE, return_geometry = TRUE,   return_map = FALSE, verbose = FALSE)"},{"path":"/reference/redistribute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Redistribute Data — redistribute","text":"source matrix-like object want distribute ; usually real complete dataset, often lower resolution / higher level. target matrix-like object want distribute : usually dataset want available, often higher resolution / lower level (disaggregation). Can also single number, representing number initial characters source IDs derive target IDs (useful aggregating nested groups). map list entries named source IDs (aligning IDs), containing vectors associated target IDs (indices IDs). Entries can also numeric vectors IDs names, used weigh relationship. IDs related substrings (first characters target IDs source IDs), map can automatically generated . source target contain sf geometries, map made st_intersects (st_intersects(source, target)). intersects map made, source aggregated target, map entries contain multiple target IDs, entries weighted proportion overlap source area. source_id, target_id Name column source / target, vector containing IDs. source, default first column. target, columns searched one appears relate source IDs, falling back first column. weight Name column, vector containing weights (single value apply cases), apply target disaggregating, source aggregating. Defaults unit weights (weights 1). source_variable, source_value source tall (variables spread across rows rather columns), specifies names columns source containing variable names values conversion. aggregate Logical; specified, determine whether aggregate disaggregate source target. Otherwise, TRUE source observations target observations. weight_agg_method Means aggregating weight, case target IDs contain duplicates. Options \"sum\", \"average\", \"auto\" (default; sum weight integer-like, average otherwise). outFile Path CSV file save results. overwrite Logical; TRUE, overwrite existing outFile. make_intersect_map Logical; TRUE, opt calculate intersect-based map rather ID-based map, seem possible. specified FALSE, never calculate intersect-based map. overlaps specified TRUE \"keep\", assign target entities mapped multiple source entities single source entity. value determines entities weight assigned, \"first\" (default), \"last\", \"random\". use_all Logical; TRUE (default), redistribute map weights sum 1. Otherwise, entities may partially weighted. return_geometry Logical; FALSE, set returned data.frame's geometry target, exists. return_map Logical; TRUE, return map, without performing redistribution. Useful want inspect automatically created map, use later call. verbose Logical; TRUE, show status messages.","code":""},{"path":"/reference/redistribute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Redistribute Data — redistribute","text":"data.frame row target_ids (identified first column, id), column variable source.","code":""},{"path":"/reference/redistribute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Redistribute Data — redistribute","text":"","code":"# minimal example source <- c(a = 1, b = 2) target <- 1:5 (redistribute(source, target, verbose = TRUE)) #> ℹ source IDs: 1 #> ℹ target IDs: `target` vector #> ℹ map: all target IDs for single source #> ℹ weights: 1 #> ℹ redistributing 2 variables from 1 source to 5 targets: #> • (numb; 2) a, b #> ℹ disaggregating... #> ✔ done disaggregating [8ms] #>  #>   id   a   b #> 1  1 0.2 0.4 #> 2  2 0.2 0.4 #> 3  3 0.2 0.4 #> 4  4 0.2 0.4 #> 5  5 0.2 0.4  # multi-entity example source <- data.frame(id = c(\"a\", \"b\"), cat = c(\"aaa\", \"bbb\"), num = c(1, 2)) target <- data.frame(   id = sample(paste0(c(\"a\", \"b\"), rep(1:5, 2))),   population = sample.int(1e5, 10) ) (redistribute(source, target, verbose = TRUE)) #> ℹ source IDs: id column of `source` #> ℹ target IDs: id column of `target` #> ℹ map: first 1 character of target IDs #> ℹ weights: 1 #> ℹ redistributing 2 variables from 2 sources to 10 targets: #> • (numb; 1) num #> • (char; 1) cat #> ℹ disaggregating... #> ✔ done disaggregating [6ms] #>  #> ℹ re-converting categorical levels #>    id cat num #> 1  a4 aaa 0.2 #> 2  a2 aaa 0.2 #> 3  b3 bbb 0.4 #> 4  b2 bbb 0.4 #> 5  a1 aaa 0.2 #> 6  b4 bbb 0.4 #> 7  b5 bbb 0.4 #> 8  b1 bbb 0.4 #> 9  a3 aaa 0.2 #> 10 a5 aaa 0.2"}]
